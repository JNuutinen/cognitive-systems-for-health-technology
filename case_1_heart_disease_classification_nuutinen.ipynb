{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# <p style=\"text-align: center;\">Case 1: Heart disease classification</p>\n",
    "\n",
    "### <p style=\"text-align: center;\">Juha Nuutinen</p>\n",
    "\n",
    "### <p style=\"text-align: center;\">20.01.2019</p>\n",
    "\n",
    "### <p style=\"text-align: center;\">Helsinki Metropolia University of Applied Sciences</p>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Objectives\n",
    "This notebook documents the process of using neural networks to try and predict some kind of heart disease for an individual from a set of their biological attributes.\n",
    "\n",
    "The goals of this assignment are to learn to use Python for machine learning with neural networks (from the `keras` library), read data from external sources using the `pandas` library, visualize data with `matplotlib`, and document the results clearly.\n",
    "Learning to use the neural network includes testing of different model architectures (number of layers, number of units, activation functions), and solver optimizers and training settings (epochs, batch sizes, validation splits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data\n",
    "\n",
    "### Origin\n",
    "\n",
    "The data is provided by <a href=\"https://archive.ics.uci.edu/ml/index.php\">UC Irvine Machine Learning Repository</a>, and the data folder can be found <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/\">here</a>. For this assignment, we are going to use the preprocessed data from Cleveland Clinic Foundation (`processed.cleveland.data`). The principal investigator responsible for the collection of the data is Robert Detrano, M.D., Ph.D. in Cleveland Clinic Foundation. The data is from the year 1988.\n",
    "\n",
    "### Description\n",
    "\n",
    "All information and numbers in this section are taken from the <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/heart-disease.names\">`heart-disease.names`</a> file. The data is in CSV (Comma Separated Values) format and it contains a total of 303 instances. Each instance has 14 attributes. The non-processed data contained originally a total of 76 attributes. Missing values are encoded with a question mark (?).\n",
    "\n",
    "A list of the attributes in each instance:\n",
    "1. age\n",
    "    * Age in years, numeric\n",
    "2. sex\n",
    "    * Nominal\n",
    "    * 1 = male\n",
    "    * 0 = female\n",
    "3. cp\n",
    "    * Chest pain type, nominal\n",
    "    * 1 = typical angina\n",
    "    * 2 = atypical angina\n",
    "    * 3 = non-anginal pain\n",
    "    * 4 = asymptomatic\n",
    "4. trestbps\n",
    "    * Resting blood pressure in mm Hg, numeric\n",
    "5. chol\n",
    "    * Serum cholestoral in mg/dl, numeric\n",
    "6. fbs\n",
    "    * Fasting blood sugar > 120 mg/dl, nominal\n",
    "    * 1 = true\n",
    "    * 0 = false\n",
    "7. restecg\n",
    "    * Resting electrocardiaographic results, nominal\n",
    "    * 0 = normal\n",
    "    * 1 = having ST-T wave abnormality (T  wave inversions and/or ST elevation or depression of > 0.05mV\n",
    "    * 2 = showing probable or definite left ventricular hypertrophy by  Estes' criteria\n",
    "8. thalach\n",
    "    * Maximum heart rate achieved, numeric\n",
    "9. exang\n",
    "    * Exercise induced angina, nominal\n",
    "    * 1 = yes\n",
    "    * 0 = no\n",
    "10. oldpeak\n",
    "    * St depression induced by exercise relative to rest, numeric\n",
    "11. slope\n",
    "    * The slope of the peak exercise relative to rest, nominal\n",
    "    * 1 = upslopping\n",
    "    * 2 = flat\n",
    "    * 3 = downslopping\n",
    "12. ca\n",
    "    * Number of major vessels (0-3) colored by flourosopy, numeric\n",
    "13. thal\n",
    "    * Nominal\n",
    "    * 3 = normal\n",
    "    * 6 = fixed defect\n",
    "    * 7 = reversable defect\n",
    "14. num (the predicted value)\n",
    "    * Diagnosis of heart disease (angiographic disease status), nominal\n",
    "    * 0 = absence of disease\n",
    "    * 1, 2, 3, 4 = presence of disease\n",
    "\n",
    "In this data set, there are a total of 164 disease-free instances (num = 0), and 139 instances with disease (num = 1, 2, 3 or 4), totaling to 303 instances.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "#### Read in the data\n",
    "The data is read into a pandas DataFrame in the cell below. Also the column names are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  sex   cp  trestbps   chol  fbs  restecg  thalac  exang  oldpeak  \\\n",
      "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0   132.0    0.0      1.2   \n",
      "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0   141.0    0.0      3.4   \n",
      "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0   115.0    1.0      1.2   \n",
      "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0   174.0    0.0      0.0   \n",
      "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0   173.0    0.0      0.0   \n",
      "\n",
      "     slope   ca  thal  num  \n",
      "298    2.0  0.0   7.0    1  \n",
      "299    2.0  2.0   7.0    2  \n",
      "300    2.0  1.0   7.0    3  \n",
      "301    2.0  1.0   3.0    1  \n",
      "302    1.0  NaN   3.0    0  \n"
     ]
    }
   ],
   "source": [
    "url = r'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "dataframe = pd.read_csv(url, \n",
    "                        sep = ',', \n",
    "                        header = None, \n",
    "                        index_col = None,\n",
    "                        na_values = '?')\n",
    "\n",
    "# The CSV data does not contain a header row, so the column names\n",
    "# must be set manually.\n",
    "names = ['age', 'sex', 'cp','trestbps', 'chol', 'fbs','restecg',\n",
    "         'thalac','exang','oldpeak','slope','ca','thal','num']\n",
    "\n",
    "dataframe.columns = names\n",
    "print(dataframe.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the missing (NaN) value in the excerpt above.\n",
    "#### Set column (attribute) types\n",
    "The attributes 2 (sex), 3 (cp), 6 (fbs), 7 (restecg), 9 (exang), 11 (slope) 13 (thal) and 14 (num) are nominal, all other are numeric. Column types are converted appropriately in the cell below. We'll only need to change the type of the nominal columns to categorical, as all columns are by fedault interpreted as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age          float64\n",
      "sex         category\n",
      "cp          category\n",
      "trestbps     float64\n",
      "chol         float64\n",
      "fbs         category\n",
      "restecg     category\n",
      "thalac       float64\n",
      "exang       category\n",
      "oldpeak      float64\n",
      "slope       category\n",
      "ca           float64\n",
      "thal        category\n",
      "num         category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataframe = dataframe.astype({\"sex\": 'category',\n",
    "                              \"cp\": 'category',\n",
    "                              \"fbs\": 'category',\n",
    "                              \"restecg\": 'category',\n",
    "                              \"exang\": 'category',\n",
    "                              \"slope\": 'category',\n",
    "                              \"thal\": 'category',\n",
    "                              \"num\": 'category'})\n",
    "print(dataframe.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill missing values\n",
    "Next the missing values are replaces with mean values for the corresponding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of missing values: 6\n",
      "\n",
      "      age  sex   cp  trestbps   chol  fbs restecg  thalac exang  oldpeak  \\\n",
      "298  45.0  1.0  1.0     110.0  264.0  0.0     0.0   132.0   0.0      1.2   \n",
      "299  68.0  1.0  4.0     144.0  193.0  1.0     0.0   141.0   0.0      3.4   \n",
      "300  57.0  1.0  4.0     130.0  131.0  0.0     0.0   115.0   1.0      1.2   \n",
      "301  57.0  0.0  2.0     130.0  236.0  0.0     2.0   174.0   0.0      0.0   \n",
      "302  38.0  1.0  3.0     138.0  175.0  0.0     0.0   173.0   0.0      0.0   \n",
      "\n",
      "    slope   ca thal num  \n",
      "298   2.0  0.0  7.0   1  \n",
      "299   2.0  2.0  7.0   2  \n",
      "300   2.0  1.0  7.0   3  \n",
      "301   2.0  1.0  3.0   1  \n",
      "302   1.0  0.0  3.0   0  \n",
      "\n",
      "Total number of missing values after filling them (should be 0): 0\n"
     ]
    }
   ],
   "source": [
    "# Check how many missing values there are.\n",
    "# Missing values are '?' in the original data, but in the read_csv\n",
    "# line in an earlier cell, they were converted to NaNs, which are the default representation\n",
    "# for missing values in Pandas.\n",
    "print(\"Total number of missing values: \" + str(dataframe.isnull().sum().sum()) + \"\\n\")\n",
    "\n",
    "dataframe = dataframe.fillna(dataframe.median())\n",
    "print(dataframe.tail())\n",
    "\n",
    "print(\"\\nTotal number of missing values after filling them (should be 0): \"\n",
    "      + str(dataframe.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above excerpt is compared with the one shown earlier, we'll see that the \"ca\" value that was NaN earlier is now replaced with a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling and compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_dim=13),\n",
    "    Activation('relu'),\n",
    "    Dense(1),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and validation\n",
    "The data must be separated to two separate DataFrames for training. One DataFrame must include all other attributes than the label attribute (\"num\" in this case), and the other DataFrame must include only the correct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 0.9997 - acc: 0.1815\n",
      "Epoch 2/5\n",
      "303/303 [==============================] - 0s 99us/step - loss: 0.9997 - acc: 0.1815\n",
      "Epoch 3/5\n",
      "303/303 [==============================] - 0s 101us/step - loss: 0.9997 - acc: 0.1815\n",
      "Epoch 4/5\n",
      "303/303 [==============================] - 0s 111us/step - loss: 0.9997 - acc: 0.1815\n",
      "Epoch 5/5\n",
      "303/303 [==============================] - 0s 154us/step - loss: 0.9997 - acc: 0.1815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd25b745f8>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = dataframe.loc[:, 'age':'thal']\n",
    "training_labels = dataframe.loc[:, 'num']\n",
    "\n",
    "model.fit(training_data, training_labels, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-89c7d928d47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
